t-критерий Стьюдента — общее название для класса методов статистической проверки гипотез (статистических критериев), основанных на распределении Стьюдента. Наиболее частые случаи применения t-критерия связаны с проверкой равенства средних значений в двух выборках.
t-статистика строится обычно по следующему общему принципу: в числителе — случайная величина с нулевым математическим ожиданием (при выполнении нулевой гипотезы), а в знаменателе — выборочное стандартное отклонение этой случайной величины, получаемое как квадратный корень из несмещённой оценки дисперсии.


== История ==
Данный критерий был разработан Уильямом Госсетом для оценки качества пива в компании Гиннесс. В связи с обязательствами перед компанией по неразглашению коммерческой тайны (руководство Гиннесса считало таковой использование статистического аппарата в своей работе), статья Госсета вышла в 1908 году в журнале «Биометрика» под псевдонимом «Student» (Студент).


== Требования к данным ==
Для применения данного критерия необходимо, чтобы исходные данные имели нормальное распределение. В случае применения двухвыборочного критерия для независимых выборок также необходимо соблюдение условия равенства дисперсий. Существуют, однако, альтернативы критерию Стьюдента для ситуации с неравными дисперсиями.
Требование нормальности распределения данных является необходимым для точного 
  
    
      
        t
      
    
    {\displaystyle t}
  -теста. Однако, даже при других распределениях данных возможно использование 
  
    
      
        t
      
    
    {\displaystyle t}
  -статистики. Во многих случаях эта статистика асимптотически имеет стандартное нормальное распределение — 
  
    
      
        N
        (
        0
        ,
        1
        )
      
    
    {\displaystyle N(0,1)}
  , поэтому можно использовать квантили этого распределения. Однако часто даже в этом случае используют квантили не стандартного нормального распределения, а соответствующего распределения Стьюдента, как в точном 
  
    
      
        t
      
    
    {\displaystyle t}
  -тесте. Асимптотически они эквивалентны, однако на малых выборках доверительные интервалы распределения Стьюдента шире и надёжнее.
При несоблюдении этих условий при сравнении выборочных средних должны использоваться аналогичные методы непараметрической статистики, среди которых наиболее известными являются U-критерий Манна — Уитни (в качестве двухвыборочного критерия для независимых выборок), а также критерий знаков и критерий Уилкоксона (используются в случаях зависимых выборок).


== Одновыборочный t-критерий ==
Применяется для проверки нулевой гипотезы 
  
    
      
        
          H
          
            0
          
        
        :
        E
        (
        X
        )
        =
        m
      
    
    {\displaystyle H_{0}:E(X)=m}
   о равенстве математического ожидания 
  
    
      
        E
        (
        X
        )
      
    
    {\displaystyle E(X)}
   некоторому известному значению 
  
    
      
        m
      
    
    {\displaystyle m}
  .
Очевидно, при выполнении нулевой гипотезы 
  
    
      
        E
        (
        
          
            X
            ¯
          
        
        )
        =
        m
      
    
    {\displaystyle E({\overline {X}})=m}
  . С учётом предполагаемой независимости наблюдений 
  
    
      
        V
        (
        
          
            X
            ¯
          
        
        )
        =
        
          σ
          
            2
          
        
        
          /
        
        n
      
    
    {\displaystyle V({\overline {X}})=\sigma ^{2}/n}
  . Используя несмещённую оценку дисперсии 
  
    
      
        
          s
          
            X
          
          
            2
          
        
        =
        
          ∑
          
            t
            =
            1
          
          
            n
          
        
        (
        
          X
          
            t
          
        
        −
        
          
            X
            ¯
          
        
        
          )
          
            2
          
        
        
          /
        
        (
        n
        −
        1
        )
      
    
    {\displaystyle s_{X}^{2}=\sum _{t=1}^{n}(X_{t}-{\overline {X}})^{2}/(n-1)}
   получаем следующую t-статистику:

  
    
      
        t
        =
        
          
            
              
                
                  X
                  ¯
                
              
              −
              m
            
            
              
                s
                
                  X
                
              
              
                /
              
              
                
                  n
                
              
            
          
        
        .
      
    
    {\displaystyle t={\frac {{\overline {X}}-m}{s_{X}/{\sqrt {n}}}}.}
  

При нулевой гипотезе распределение этой статистики 
  
    
      
        t
        (
        n
        −
        1
        )
      
    
    {\displaystyle t(n-1)}
  . Следовательно, при превышении значения статистики по абсолютной величине критического значения данного распределения (при заданном уровне значимости) нулевая гипотеза отвергается.


== Двухвыборочный t-критерий для независимых выборок ==
Пусть имеются две независимые выборки объёмами 
  
    
      
        
          n
          
            1
          
        
         
        ,
         
        
          n
          
            2
          
        
      
    
    {\displaystyle n_{1}~,~n_{2}}
   нормально распределённых случайных величин 
  
    
      
        
          X
          
            1
          
        
        ,
         
        
          X
          
            2
          
        
      
    
    {\displaystyle X_{1},~X_{2}}
  . Необходимо проверить по выборочным данным нулевую гипотезу равенства математических ожиданий этих случайных величин 
  
    
      
        
          H
          
            0
          
        
        :
         
        
          M
          
            1
          
        
        =
        
          M
          
            2
          
        
      
    
    {\displaystyle H_{0}:~M_{1}=M_{2}}
  .
Рассмотрим разность выборочных средних 
  
    
      
        Δ
        =
        
          
            
              X
              ¯
            
          
          
            1
          
        
        −
        
          
            
              X
              ¯
            
          
          
            2
          
        
      
    
    {\displaystyle \Delta ={\overline {X}}_{1}-{\overline {X}}_{2}}
  . Очевидно, если нулевая гипотеза выполнена, 
  
    
      
        E
        (
        Δ
        )
        =
        
          M
          
            1
          
        
        −
        
          M
          
            2
          
        
        =
        0
      
    
    {\displaystyle E(\Delta )=M_{1}-M_{2}=0}
  . Исходя из независимости выборок дисперсия этой разности равна: 
  
    
      
        V
        (
        Δ
        )
        =
        
          
            
              σ
              
                1
              
              
                2
              
            
            
              n
              
                1
              
            
          
        
        +
        
          
            
              σ
              
                2
              
              
                2
              
            
            
              n
              
                2
              
            
          
        
      
    
    {\displaystyle V(\Delta )={\frac {\sigma _{1}^{2}}{n_{1}}}+{\frac {\sigma _{2}^{2}}{n_{2}}}}
  . Тогда, используя несмещённую оценку дисперсии 
  
    
      
        
          s
          
            2
          
        
        =
        
          
            
              
                ∑
                
                  t
                  =
                  1
                
                
                  n
                
              
              (
              
                X
                
                  t
                
              
              −
              
                
                  X
                  ¯
                
              
              
                )
                
                  2
                
              
            
            
              n
              −
              1
            
          
        
      
    
    {\displaystyle s^{2}={\frac {\sum _{t=1}^{n}(X_{t}-{\overline {X}})^{2}}{n-1}}}
  , получаем несмещённую оценку дисперсии разности выборочных средних: 
  
    
      
        
          s
          
            Δ
          
          
            2
          
        
        =
        
          
            
              s
              
                1
              
              
                2
              
            
            
              n
              
                1
              
            
          
        
        +
        
          
            
              s
              
                2
              
              
                2
              
            
            
              n
              
                2
              
            
          
        
      
    
    {\displaystyle s_{\Delta }^{2}={\frac {s_{1}^{2}}{n_{1}}}+{\frac {s_{2}^{2}}{n_{2}}}}
  . Следовательно, t-статистика для проверки нулевой гипотезы равна

  
    
      
        t
        =
        
          
            
              
                
                  
                    X
                    ¯
                  
                
                
                  1
                
              
              −
              
                
                  
                    X
                    ¯
                  
                
                
                  2
                
              
            
            
              
                
                  
                    s
                    
                      1
                    
                    
                      2
                    
                  
                  
                    n
                    
                      1
                    
                  
                
              
              +
              
                
                  
                    s
                    
                      2
                    
                    
                      2
                    
                  
                  
                    n
                    
                      2
                    
                  
                
              
            
          
        
        .
      
    
    {\displaystyle t={\frac {{\overline {X}}_{1}-{\overline {X}}_{2}}{\sqrt {{\frac {s_{1}^{2}}{n_{1}}}+{\frac {s_{2}^{2}}{n_{2}}}}}}.}
  

Эта статистика при справедливости нулевой гипотезы имеет распределение 
  
    
      
        t
        (
        d
        f
        )
      
    
    {\displaystyle t(df)}
  , где 
  
    
      
        d
        f
        =
        
          
            
              (
              
                s
                
                  1
                
                
                  2
                
              
              
                /
              
              
                n
                
                  1
                
              
              +
              
                s
                
                  2
                
                
                  2
                
              
              
                /
              
              
                n
                
                  2
                
              
              
                )
                
                  2
                
              
            
            
              (
              
                s
                
                  1
                
                
                  2
                
              
              
                /
              
              
                n
                
                  1
                
              
              
                )
                
                  2
                
              
              
                /
              
              (
              
                n
                
                  1
                
              
              −
              1
              )
              +
              (
              
                s
                
                  2
                
                
                  2
                
              
              
                /
              
              
                n
                
                  2
                
              
              
                )
                
                  2
                
              
              
                /
              
              (
              
                n
                
                  2
                
              
              −
              1
              )
            
          
        
      
    
    {\displaystyle df={\frac {(s_{1}^{2}/n_{1}+s_{2}^{2}/n_{2})^{2}}{(s_{1}^{2}/n_{1})^{2}/(n_{1}-1)+(s_{2}^{2}/n_{2})^{2}/(n_{2}-1)}}}
  .


=== Случай одинаковой дисперсии ===
В случае, если дисперсии выборок предполагаются одинаковыми, то

  
    
      
        V
        (
        Δ
        )
        =
        
          σ
          
            2
          
        
        
          (
          
            
              
                1
                
                  n
                  
                    1
                  
                
              
            
            +
            
              
                1
                
                  n
                  
                    2
                  
                
              
            
          
          )
        
        .
      
    
    {\displaystyle V(\Delta )=\sigma ^{2}\left({\frac {1}{n_{1}}}+{\frac {1}{n_{2}}}\right).}
  
Тогда t-статистика равна:

  
    
      
        t
        =
        
          
            
              
                
                  
                    X
                    ¯
                  
                
                
                  1
                
              
              −
              
                
                  
                    X
                    ¯
                  
                
                
                  2
                
              
            
            
              
                s
                
                  X
                
              
              
                
                  
                    
                      1
                      
                        n
                        
                          1
                        
                      
                    
                  
                  +
                  
                    
                      1
                      
                        n
                        
                          2
                        
                      
                    
                  
                
              
            
          
        
         
        ,
         
         
        
          s
          
            X
          
        
        =
        
          
            
              
                (
                
                  n
                  
                    1
                  
                
                −
                1
                )
                
                  s
                  
                    1
                  
                  
                    2
                  
                
                +
                (
                
                  n
                  
                    2
                  
                
                −
                1
                )
                
                  s
                  
                    2
                  
                  
                    2
                  
                
              
              
                
                  n
                  
                    1
                  
                
                +
                
                  n
                  
                    2
                  
                
                −
                2
              
            
          
        
        .
      
    
    {\displaystyle t={\frac {{\overline {X}}_{1}-{\overline {X}}_{2}}{s_{X}{\sqrt {{\frac {1}{n_{1}}}+{\frac {1}{n_{2}}}}}}}~,~~s_{X}={\sqrt {\frac {(n_{1}-1)s_{1}^{2}+(n_{2}-1)s_{2}^{2}}{n_{1}+n_{2}-2}}}.}
  
Эта статистика имеет распределение 
  
    
      
        t
        (
        
          n
          
            1
          
        
        +
        
          n
          
            2
          
        
        −
        2
        )
      
    
    {\displaystyle t(n_{1}+n_{2}-2)}
  .


== Двухвыборочный t-критерий для зависимых выборок ==
Для вычисления эмпирического значения 
  
    
      
        t
      
    
    {\displaystyle t}
  -критерия в ситуации проверки гипотезы о различиях между двумя зависимыми выборками (например, двумя пробами одного и того же теста с временным интервалом) применяется следующая формула:

  
    
      
        t
        =
        
          
            
              M
              
                d
              
            
            
              
                s
                
                  d
                
              
              
                /
              
              
                
                  n
                
              
            
          
        
        ,
      
    
    {\displaystyle t={\frac {M_{d}}{s_{d}/{\sqrt {n}}}},}
  
где 
  
    
      
        
          M
          
            d
          
        
      
    
    {\displaystyle M_{d}}
   — средняя разность значений, 
  
    
      
        
          s
          
            d
          
        
      
    
    {\displaystyle s_{d}}
   — стандартное отклонение разностей, а n — количество наблюдений.
Эта статистика имеет распределение 
  
    
      
        t
        (
        n
        −
        1
        )
      
    
    {\displaystyle t(n-1)}
  .


== Проверка линейного ограничения на параметры линейной регрессии ==
С помощью t-теста можно также проверить произвольное (одно) линейное ограничение на параметры линейной регрессии, оценённой обычным методом наименьших квадратов. Пусть необходимо проверить гипотезу 
  
    
      
        
          H
          
            0
          
        
        :
        
          c
          
            T
          
        
        b
        =
        a
      
    
    {\displaystyle H_{0}:c^{T}b=a}
  . Очевидно, при выполнении нулевой гипотезы 
  
    
      
        E
        (
        
          c
          
            T
          
        
        
          
            
              b
              ^
            
          
        
        −
        a
        )
        =
        
          c
          
            T
          
        
        E
        (
        
          
            
              b
              ^
            
          
        
        )
        −
        a
        =
        0
      
    
    {\displaystyle E(c^{T}{\hat {b}}-a)=c^{T}E({\hat {b}})-a=0}
  . Здесь использовано свойство несмещённости МНК-оценок параметров модели 
  
    
      
        E
        (
        
          
            
              b
              ^
            
          
        
        )
        =
        b
      
    
    {\displaystyle E({\hat {b}})=b}
  . Кроме того, 
  
    
      
        V
        (
        
          c
          
            T
          
        
        
          
            
              b
              ^
            
          
        
        −
        a
        )
        =
        
          c
          
            T
          
        
        V
        (
        
          
            
              b
              ^
            
          
        
        )
        c
        =
        
          σ
          
            2
          
        
        
          c
          
            T
          
        
        (
        
          X
          
            T
          
        
        X
        
          )
          
            −
            1
          
        
        c
      
    
    {\displaystyle V(c^{T}{\hat {b}}-a)=c^{T}V({\hat {b}})c=\sigma ^{2}c^{T}(X^{T}X)^{-1}c}
  . Используя вместо неизвестной дисперсии её несмещённую оценку 
  
    
      
        
          s
          
            2
          
        
        =
        E
        S
        S
        
          /
        
        (
        n
        −
        k
        )
      
    
    {\displaystyle s^{2}=ESS/(n-k)}
  , получаем следующую t-статистику:

 
  
    
      
        t
        =
        
          
            
              
                c
                
                  T
                
              
              
                
                  
                    b
                    ^
                  
                
              
              −
              a
            
            
              s
              
                
                  
                    c
                    
                      T
                    
                  
                  (
                  
                    X
                    
                      T
                    
                  
                  X
                  
                    )
                    
                      −
                      1
                    
                  
                  c
                
              
            
          
        
        .
      
    
    {\displaystyle t={\frac {c^{T}{\hat {b}}-a}{s{\sqrt {c^{T}(X^{T}X)^{-1}c}}}}.}
  
Эта статистика при выполнении нулевой гипотезы имеет распределение 
  
    
      
        t
        (
        n
        −
        k
        )
      
    
    {\displaystyle t(n-k)}
  , поэтому если значение статистики выше критического, то нулевая гипотеза о линейном ограничении отклоняется.


=== Проверка гипотез о коэффициенте линейной регрессии ===
Частным случаем линейного ограничения является проверка гипотезы о равенстве коэффициента 
  
    
      
        
          b
          
            j
          
        
      
    
    {\displaystyle b_{j}}
   регрессии некоторому значению 
  
    
      
        a
      
    
    {\displaystyle a}
  . В этом случае соответствующая t-статистика равна:

  
    
      
        t
        =
        
          
            
              
                
                  
                    
                      b
                      ^
                    
                  
                
                
                  j
                
              
              −
              a
            
            
              s
              
                
                  
                    
                      
                        b
                        ^
                      
                    
                  
                  
                    j
                  
                
              
            
          
        
        ,
      
    
    {\displaystyle t={\frac {{\hat {b}}_{j}-a}{s_{{\hat {b}}_{j}}}},}
  
где 
  
    
      
        
          s
          
            
              
                
                  
                    b
                    ^
                  
                
              
              
                j
              
            
          
        
      
    
    {\displaystyle s_{{\hat {b}}_{j}}}
   — стандартная ошибка оценки коэффициента — квадратный корень из соответствующего диагонального элемента ковариационной матрицы оценок коэффициентов.
При справедливости нулевой гипотезы распределение этой статистики — 
  
    
      
        t
        (
        n
        −
        k
        )
      
    
    {\displaystyle t(n-k)}
  . Если значение статистики по абсолютной величине выше критического значения, то отличие коэффициента от 
  
    
      
        a
      
    
    {\displaystyle a}
   является статистически значимым (неслучайным), в противном случае — незначимым (случайным, то есть истинный коэффициент вероятно равен или очень близок к предполагаемому значению 
  
    
      
        a
      
    
    {\displaystyle a}
  ).


=== Замечание ===
Одновыборочный тест для математических ожиданий можно свести к проверке линейного ограничения на параметры линейной регрессии. В одновыборочном тесте это «регрессия» на константу. Поэтому 
  
    
      
        
          s
          
            2
          
        
      
    
    {\displaystyle s^{2}}
   регрессии и есть выборочная оценка дисперсии изучаемой случайной величины, матрица 
  
    
      
        
          X
          
            T
          
        
        X
      
    
    {\displaystyle X^{T}X}
   равна 
  
    
      
        n
      
    
    {\displaystyle n}
  , а оценка «коэффициента» модели равна выборочному среднему. Отсюда и получаем выражение для t-статистики, приведённое выше для общего случая.
Аналогично можно показать, что двухвыборочный тест при равенстве дисперсий выборок также сводится к проверке линейных ограничений. В двухвыборочном тесте это «регрессия» на константу и фиктивную переменную, идентифицирующую подвыборку в зависимости от значения (0 или 1): 
  
    
      
        y
        =
        a
        +
        b
        D
      
    
    {\displaystyle y=a+bD}
  . Гипотеза о равенстве математических ожиданий выборок может быть сформулирована как гипотеза о равенстве коэффициента b этой модели нулю. Можно показать, что соответствующая t-статистика для проверки этой гипотезы равна t-статистике, приведённой для двухвыборочного теста.
Также к проверке линейного ограничения можно свести и в случае разных дисперсий. В этом случае дисперсия ошибок модели принимает два значения. Исходя из этого можно также получить t-статистику, аналогичную приведённой для двухвыборочного теста.


== Непараметрические аналоги ==
Аналогом двухвыборочного критерия для независимых выборок является U-критерий Манна — Уитни. Для ситуации с зависимыми выборками аналогами являются критерий знаков и T-критерий Вилкоксона.


== Литература ==
Student. The probable error of a mean. // Biometrika. 1908. № 6 (1). P. 1-25.


== Ссылки ==
О критериях проверки гипотез об однородности средних на сайте Новосибирского государственного технического университета